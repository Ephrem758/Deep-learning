{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2234ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a963c1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseLayer:\n",
    "\n",
    "  # Layer initialization\n",
    "  def __init__(self, n_inputs, n_neurons):\n",
    "    # Initialize weights and biases\n",
    "    self.weights = 0.01 * torch.rand(n_inputs, n_neurons)\n",
    "    self.biases = torch.zeros((1, n_neurons))\n",
    "\n",
    "  # Forward pass\n",
    "  def forward(self, inputs):\n",
    "    # Calculate output values from inputs, weights and biases\n",
    "    self.output = torch.matmul(inputs, self.weights) + self.biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaaf5a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ReLU activation\n",
    "class Activation_ReLU:\n",
    "  # Forward pass\n",
    "  def forward(self, inputs):\n",
    "    self.output = torch.max(inputs, torch.tensor(0))\n",
    "    return self.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ad47b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid activation\n",
    "class Activation_Sigmoid:\n",
    "  # Forward pass\n",
    "  def forward(self, inputs):\n",
    "    self.output = 1 / (1 + torch.exp(-inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154ef8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# softmax activation\n",
    "class Activation_Softmax:\n",
    "    # Forward pass\n",
    "    def forward(self, inputs):\n",
    "        # Get unnormalized probabilities (logits)\n",
    "        exp_values = torch.exp(inputs - torch.max(inputs, dim=-1, keepdim=True)[0])\n",
    "\n",
    "        # Normalize them for each sample\n",
    "        probabilities = exp_values / torch.sum(exp_values, dim=-1, keepdim=True)\n",
    "\n",
    "        self.output = probabilities\n",
    "        return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4cdfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss_CategoricalCrossentropy():\n",
    "    def forward(self, y_pred, y_true):\n",
    "        # Ensure probabilities do not equal 0\n",
    "        y_pred_clipped = torch.clamp(y_pred, 1e-7, 1 - 1e-7)\n",
    "\n",
    "        # If targets are one-hot encoded, convert them to discrete labels\n",
    "        if len(y_true.shape) == 2:\n",
    "            y_true = torch.argmax(y_true, dim=1)\n",
    "\n",
    "        # Get the predicted probabilities for the correct classes\n",
    "        correct_confidences = y_pred_clipped[torch.arange(len(y_pred)), y_true]\n",
    "\n",
    "        # Calculate the negative log likelihood\n",
    "        negative_log_likelihoods = -torch.log(correct_confidences)\n",
    "\n",
    "        # Calculate the overall loss as the average of individual sample losses\n",
    "        loss = torch.mean(negative_log_likelihoods)\n",
    "\n",
    "        return loss\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3791f41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(y_pred, y_true):\n",
    "    # Convert predicted probabilities to class labels\n",
    "    y_pred_labels = torch.argmax(y_pred, dim=1)\n",
    "    \n",
    "    # Compare predicted labels to true labels\n",
    "    correct_predictions = (y_pred_labels == y_true).sum().item()\n",
    "    \n",
    "    # Calculate accuracy as the percentage of correct predictions\n",
    "    total_samples = len(y_true)\n",
    "    accuracy = correct_predictions / total_samples \n",
    "    \n",
    "    return accuracy\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5559e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize the layers\n",
    "\n",
    "# input layer\n",
    "layer1 = DenseLayer(4, 18)\n",
    "layer2 = DenseLayer(18, 18)\n",
    "layer3 = DenseLayer(18, 18)\n",
    "output_layer = DenseLayer(18, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0965cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "input1 = torch.rand(32, 4)\n",
    "\n",
    "layer1.forward(input1)\n",
    "relu_activation.forward(layer1.output)\n",
    "layer1.output = relu_activation.output\n",
    "\n",
    "layer2.forward(layer1.output)\n",
    "relu_activation.forward(layer2.output)\n",
    "layer2.output = relu_activation.output\n",
    "\n",
    "layer3.forward(layer2.output)\n",
    "relu_activation.forward(layer3.output)\n",
    "layer3.output = relu_activation.output\n",
    "\n",
    "output_layer.forward(layer3.output)\n",
    "softmax_activation.forward(output_layer.output)\n",
    "output_layer.output = softmax_activation.output\n",
    "\n",
    "output_layer.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe0bbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1.forward(input1)\n",
    "sigmoid_activation.forward(layer1.output)\n",
    "layer1.output = sigmoid_activation.output\n",
    "\n",
    "layer2.forward(layer1.output)\n",
    "sigmoid_activation.forward(layer2.output)\n",
    "layer2.output = sigmoid_activation.output\n",
    "\n",
    "layer3.forward(layer2.output)\n",
    "sigmoid_activation.forward(layer3.output)\n",
    "layer3.output = sigmoid_activation.output\n",
    "\n",
    "output_layer.forward(layer3.output)\n",
    "sigmoid_activation.forward(output_layer.output)\n",
    "output_layer.output = softmax_activation.output\n",
    "\n",
    "output_layer.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7615d455",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating Loss\n",
    "\n",
    "\n",
    "output_true =torch.randint(0, 3, (32,))\n",
    "loss = loss_categorical.forward(output_layer.output, output_true)\n",
    "accuracy = calculate_accuracy(output_layer.output, output_true)\n",
    "\n",
    "print(loss)\n",
    "print(accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
